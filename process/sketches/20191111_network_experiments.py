'''
Sketch of example for python based network analysis using an OSMnx derived graphml file

Assumptions
    - sample points (origins) 
        - are located along network
        - not necessarily coincident with nodes
        - associated with an OSM edge id (which is actually ogc_fid, created when importing to sql database)
        - TO DO: ensure each sample point is associated with edge 'from' and 'to' and their respective (Euclidean? Linear?) distances from sample point
    - destination points are arbitrarily located, not necessarily along the network nor coincident with nodes
        - TO DO: 
    - edges (road network segments)
        - have ogc_fid as primary key
        - have the fields 'from' and 'to' which identify the respective terminal nodes for each edge segment
        
        


Idea: 
 -- calculate and store the distances to the two nearest nodes on edges for all sample point origins
 -- calculate and store the nearest node (D-nodes) and euclidean distance to this for each destination
 -- compute distances to all nodes within 3200m from all associated D-nodes
 -- for all origin-destination combinations
        - evaluate: do the O and D share an edge?  
            - If so: take Euclidean distance between these (they are close, and a straight line representation is most likely adequate; alternative is to do a spatial operation)
            - else:
                - are any of the O-node-pairs in the list of D-node-pairs?
                    - if so: take D-node-pair - O-node-pair match with minimum distance, accounting for specific D offset
                    
            
'''

import networkx as nx
import time 
import osmnx as ox
import numpy as np
import requests
import pandas as pd
import geopandas as gpd

from sqlalchemy import create_engine
from _project_setup import *


from multiprocessing import  Pool


def create_local_nodes_dict(df,graph = G, distance = 3200):
    df[f'local_{distance}m'] = df.node.apply(lambda x: nx.multi_source_dijkstra_path_length(graph, {x}, cutoff=distance, weight='length'))
    return df


def parallelize_dataframe(df, func, n_cores=4):
    start_time = time.time()
    l = len(df)
    df_split = np.array_split(df, n_cores)
    pool = Pool(n_cores)
    df = pd.concat(pool.map(func, df_split))
    pool.close()
    pool.join()
    end_time = time.time()
    print("{} rows: {} minutes; rate per 100,000: {} minutes".format(l,(end_time-start_time)/60,(end_time-start_time)/l*100000/60))
    return df


engine = create_engine("postgresql://{user}:{pwd}@{host}/{db}".format(user = db_user,
                                                                      pwd  = db_pwd,
                                                                      host = db_host,
                                                                      db   = db))


sql = '''
ALTER TABLE sample_points_30m ADD COLUMN IF NOT EXISTS node_json

'''

# Set up network for analysis with NetworkX
start_time = time.time()
# variable for location of existing graphml xml network file, generated by OSMnx
graphml = '../data/study_region/bangkok_thailand_2018/bangkok_thailand_2018_10000m_pedestrian_osm_20190430.graphml'
# read in network
G = nx.read_graphml(graphml, node_type=str)
# ensure it is interpreted as undirected; we want our pedestrians to walk in either direction
G = nx.Graph(G)
# # length is a string (why?!), but must be an float
for u,v,d in G.edges(data=True):
   d['length'] = float(d['length'])

end_time = time.time()
print("Network x graph set up in  {:.02f} minutes".format((end_time-start_time)/60))
# For Bangkok: Network x graph set up in  1.02 minutes

# Set up output dataframe
df = pd.DataFrame(list(G.nodes),columns=['node'])

## Time tests for the node analysis:
## for l in [100,1000,10000]:
#    # start_time = time.time()
#    # # create a subset chunk dataframe, for test purposes
#    # dfs = df.iloc[0:l].copy()
#    # # 
#    # dfs['local_3200m'] = dfs.node.apply(lambda x: nx.multi_source_dijkstra_path_length(t4, {x}, cutoff=3200, weight='length'))
#    # end_time = time.time()
#    # print("{} rows: {} minutes; rate per 100,000: {} minutes".format(l,(end_time-start_time)/60,(end_time-start_time)/l*100000/60))
#
## # 100 rows: 0.00812004009882609 minutes; rate per 100,000: 8.12004009882609 minutes
## # 1000 rows: 0.10880138476689656 minutes; rate per 100,000: 10.880138476689657 minutes
## # 10000 rows: 1.2252854744593302 minutes; rate per 100,000: 12.252854744593302 minutes
# 
# 
## td = dfs.iloc[0].local_3200m
#
## # get the node with highest distance
## max(td, key=lambda key: td[key])
#
## # get the node with minimum distance
## min(td, key=lambda key: td[key])
#
## # get distance to a specific node (what we want, after determining our origin is in the list)
## node = 5674597687
## td[node]
#
#
#
## df2 = dfs.drop(columns=['local_3200m']).copy()
#
## start_time = time.time()
## parallelize_dataframe(df2,create_local_nodes_dict)
## end_time = time.time()
## print("{} rows: {:0.2f} minutes; rate per 100,000: {:0.2f} minutes".format(l,(end_time-start_time)/60,(end_time-start_time)/l*100000/60))
## # 10000 rows: 0.42 minutes; rate per 100,000: 4.24 minutes ; this is great! Three times as fast

# Calculate node relations
df = parallelize_dataframe(df,create_local_nodes_dict)



### Stuff that didn't work

# # configure search at a max distance for up to the first nearest points-of-interest
# num_pois = 1
# num_categories = len(shop) + 1 #one for each amenity, plus one extra for all of them combined


# def pandana_network_from_graphml(graphml):
    # """
    # Load Pandana network from graphml file.
    
    # Parameters
    # ----------
    # graphml : string
        # Graphml network file path
    # Returns
    # -------
    # pandana network
    # """
    # start_time = time.time()
    # file = os.path.basename(graphml)
    # folder = os.path.dirname(graphml)
    # if os.path.isfile(graphml):
        # method = 'loaded from graphml'
        # G = ox.load_graphml(file, folder)
        # # get gdf nodes and edges
        # gdf_nodes = ox.graph_to_gdfs(G, nodes=True, edges=False)
        # gdf_edges = ox.graph_to_gdfs(G, nodes=False, edges=True)
        # # get network from Pandana
        # network=pandana.network.Network(gdf_nodes["x"], gdf_nodes["y"], gdf_edges["u"], gdf_edges["v"],
                 # gdf_edges[["length"]])
        # print('Network with {:,} nodes {} in {:,.2f} secs'.format(len(network.node_ids), method, time.time()-start_time))
        # return network  
    # else:
        # print('The supplied graphml file path does not appear to be valid.')
        
# def get_nearest_node_to_pois(pandana_network, pois_df, distance, num_pois):
    # """
    # get nearest nodes of pois within designated distance threshold
    
    # Parameters
    # ----------
    # pandana_network : network graph
        # pandana OSM street network graph
    # pois_df : dataframe
        # point of interest dataframe
    # distance : float
        # distance threshold
    # num_pois : int
        # number of point of interest to search
    # Returns
    # -------
    # dataframe
    # """

    # # precomputes the range queries (the reachable nodes within this maximum distance)
    # # so, as long as you use a smaller distance, cached results will be used
    # start_time = time.time()
    # pandana_network.precompute(distance + 1)
    
    # # initialize a category for all amenities with the locations specified by the lon and lat columns
    # pandana_network.set_pois(category='all', maxdist=distance, maxitems=num_pois, x_col=pois_df['lon'], y_col=pois_df['lat'])

    # # searches for the n nearest amenities (of all types) to each node in the network
    # all_access = pandana_network.nearest_pois(distance=distance, category='all', num_pois=num_pois)

    # # it returned a df with the number of columns equal to the number of POIs that are requested
    # # each cell represents the network distance from the node to each of the n POIs
    # print('{:,} nodes in {:,.2f} secs'.format(len(all_access), time.time()-start_time))
    # return all_access


# sql = '''
# SELECT 
        # dest_oid, 
        # osm_id, 
        # dest_name, 
        # dest_name_full, 
        # ST_X(geom) AS lon, 
        # ST_y(geom) AS lat,
        # geom
# FROM
# (SELECT dest_oid, osm_id, dest_name, dest_name_full, ST_Transform(geom,4326) geom FROM osm_destinations) t
# '''

# test.set_pois(category='all', maxdist=3200, maxitems=100000, x_col=test.nodes_df['x'], y_col=test.nodes_df['y'])


# t2 = ox.graph_from_file(graphml, bidirectional=True, simplify=True, retain_all=False)



# # all_pairs = nx.all_pairs_dijkstra_path_length(t4, cutoff=3200,weight='length')

# # start = time.time()
# # for src in t4.nodes():
    # # # look up the id as desired                           
    # # id_src = t4.nodes[src].get('id')
    # # for dest in t4.nodes():                                                       
        # # id_dest =  t4.nodes[dest].get('id')                                    
        # # l = all_pairs.get(src).get(dest)                                  
        # # print("{}, {}, {}".format(id_src, id_dest, l)) 

# # end = time.time()



# # test networkx method using OMSnx borrowed get nearest nodes

# # # build a k-d tree for euclidean nearest node search
# # nodes = pd.DataFrame({'x':nx.get_node_attributes(t4, 'x'),
                      # # 'y':nx.get_node_attributes(t4, 'y')})
# # tree = cKDTree(data=nodes[['x', 'y']], compact_nodes=True, balanced_tree=True)

# # # query the tree for nearest node to each point
# # points = np.array([X, Y]).T
# # dist, idx = tree.query(points, k=1)
# # nn = nodes.iloc[idx].index



# # test_chunk = nx.multi_source_dijkstra_path_length(t4, {6004249984}, cutoff=3200, weight='length')
# # df = pd.DataFrame.from_records(test_chunk)
